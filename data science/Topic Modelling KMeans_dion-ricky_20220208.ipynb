{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dionrickysptr/future-data-2/venv/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from joblib import dump\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "\n",
    "# Google cloud\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "from keras.preprocessing.text import tokenizer_from_json\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from util.text_preprocessing import StopWordRemoverFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_path = '../airflow/credentials/future-data-track-1-sapporo.json'\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    key_path,\n",
    "    scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    ")\n",
    "\n",
    "bigquery_client = bigquery.Client(\n",
    "    project='future-data-track-1',\n",
    "    credentials=credentials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT * FROM `future-data-track-1.sapporo_mart.topic_modelling`;\n",
    "\"\"\"\n",
    "\n",
    "query_job = bigquery_client.query(query)\n",
    "df = query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>created_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gp:AOqpTOHajl5LbNjh0p68FTNBcucXHLImtaMplr41M46...</td>\n",
       "      <td>Tolong lah sehari saja berhenti memberikan not...</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-09 11:31:09+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gp:AOqpTOE9wwn04N2P0KF0lHaitBTIsIt-m0vScdPZqRg...</td>\n",
       "      <td>Ngiklan mulu</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-18 12:47:35+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gp:AOqpTOEXVM0HpOd0hh2KKQ2npUye4nYaN9YCBTt3lq6...</td>\n",
       "      <td>Be be be</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-25 17:48:18+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gp:AOqpTOHdVMTWvbJ-6mTQ2q8DLDwOU7Re7-GS9uICWoj...</td>\n",
       "      <td>Iklan asu</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-08-12 08:04:34+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gp:AOqpTOFkWvobwA7CgtroIIy-mrzSWYtzvBtU5SXWKPj...</td>\n",
       "      <td>Pengiriman lama. Barang yang di kirim banyak y...</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-19 15:51:43+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           review_id  \\\n",
       "0  gp:AOqpTOHajl5LbNjh0p68FTNBcucXHLImtaMplr41M46...   \n",
       "1  gp:AOqpTOE9wwn04N2P0KF0lHaitBTIsIt-m0vScdPZqRg...   \n",
       "2  gp:AOqpTOEXVM0HpOd0hh2KKQ2npUye4nYaN9YCBTt3lq6...   \n",
       "3  gp:AOqpTOHdVMTWvbJ-6mTQ2q8DLDwOU7Re7-GS9uICWoj...   \n",
       "4  gp:AOqpTOFkWvobwA7CgtroIIy-mrzSWYtzvBtU5SXWKPj...   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  Tolong lah sehari saja berhenti memberikan not...       1   \n",
       "1                                       Ngiklan mulu       1   \n",
       "2                                           Be be be       1   \n",
       "3                                          Iklan asu       1   \n",
       "4  Pengiriman lama. Barang yang di kirim banyak y...       1   \n",
       "\n",
       "               created_date  \n",
       "0 2020-11-09 11:31:09+00:00  \n",
       "1 2021-04-18 12:47:35+00:00  \n",
       "2 2021-04-25 17:48:18+00:00  \n",
       "3 2021-08-12 08:04:34+00:00  \n",
       "4 2021-05-19 15:51:43+00:00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_sw_remover = StopWordRemoverFactory().create_stop_word_remover()\n",
    "\n",
    "sw_remover = _sw_remover.remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(value):\n",
    "    # value = value.lower()\n",
    "    value = re.sub(r'<.*?>', '', value)\n",
    "    value = re.sub(r'[^a-zA-Z]', ' ', value)\n",
    "    value = re.sub(r'\\s\\s+', ' ', value)\n",
    "    # value = stemmer(value)\n",
    "    value = sw_remover(value)\n",
    "    value = list(filter(lambda x: x, [x.lower() for x in value.split(\" \")]))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'].replace('', float(\"NaN\"))\n",
    "df.dropna(subset=[\"review\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts =  df['review'].apply(lambda x : preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_kmeans = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "#                     ('kmeans', KMeans())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_kmeans.fit(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_file = open('Sentiment Analysis/Tokenizer/tokens_30k.json', 'r')\n",
    "\n",
    "tokenizer = tokenizer_from_json(tokenizer_file.read())\n",
    "\n",
    "tokenizer_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding\n",
    "seq = tokenizer.texts_to_sequences(df['review'])\n",
    "X = pad_sequences(seq, maxlen=120, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILEPATH = 'Sentiment Analysis/Embedding/w2v_emoji_sw_v4.w2v'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Word2Vec.load(EMBEDDING_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_matrix(embedding: Word2Vec, vocab):\n",
    "    vocab_size = len(vocab) + 1\n",
    "\n",
    "    weight_matrix = np.zeros((vocab_size, 100))\n",
    "\n",
    "    for word, i in vocab.items():\n",
    "        try:\n",
    "            weight_matrix[i] = embedding.wv.get_vector(word)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vectors = get_weight_matrix(embedding, tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(embedding_vectors, tokens):\n",
    "    vectors = []\n",
    "    \n",
    "    for token_id in tokens:\n",
    "        try:\n",
    "            vectors.append(embedding_vectors[token_id])\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [get_vectors(embedding_vectors, tokens) for tokens in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = KMeans()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9bb25bc732f7dedd2d49b595a113c80320e22d6c17d7e5452507f52d8416cf12"
  },
  "kernelspec": {
   "display_name": "Python 3.6.15 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
