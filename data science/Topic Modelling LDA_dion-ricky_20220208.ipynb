{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation\n",
    "\n",
    "The purpose of applying the LDA method is to obtain the distribution of words that make up a topic and documents with a particular topic. The first stage in LDA modeling is to initialize the parameters. These parameters can be the number of documents, the number of words in the document, the number of topics, the number of iterations, and the LDA coefficient. The next stage is to mark a word with a predetermined topic by applying a semi-random distribution based on the Dirichlet distribution method. Next is the iteration stage. In this stage, there are parameters that can determine the distribution of the number of topics and the distribution of words from topics in a document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install google-cloud-bigquery\n",
    "# %pip install PySastrawi\n",
    "# %pip install nltk\n",
    "# %pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dionrickysptr/future-data-2/venv/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamulticore import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "from util.text_preprocessing import LDAStopWordRemoverFactory, \\\n",
    "    LDAStemming, LDAFormalization, LDATextTokenizer, \\\n",
    "    LDATextPreprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess\n",
    "\n",
    "This process include casefolding, remove special character, multiple whitespace, stopword, and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_sw_remover = LDAStopWordRemoverFactory().create_stop_word_remover()\n",
    "_stemmer = LDAStemming()\n",
    "_tokenizer = LDATextTokenizer()\n",
    "_formalizer = LDAFormalization()\n",
    "\n",
    "sw_remover = _sw_remover.remove\n",
    "stemmer = _stemmer.stem\n",
    "tokenizer = _tokenizer.tokenize\n",
    "formalizer = _formalizer.convert_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = LDATextPreprocess(sw_remover, stemmer, tokenizer, formalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LdaModel.load('Topic Modelling/lda_4_dion-ricky')\n",
    "# model = LdaModel.load('LDA_4topics_with_stemming_alpha_topics_eta_len_dictionary_iter200_passes40_kaniku_20220207/lda_stem_alpha_topics_eta_lendictionary_iter200_passes40_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = model.id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.194*\"aplikasi\" + 0.140*\"belanja\" + 0.066*\"ongkir\" + 0.047*\"gratis\" + 0.032*\"online\" + 0.028*\"murah\" + 0.019*\"promo\" + 0.017*\"diskon\" + 0.013*\"unduh\" + 0.013*\"voucher\"'),\n",
       " (1,\n",
       "  '0.081*\"mudah\" + 0.071*\"barang\" + 0.061*\"belanja\" + 0.051*\"cepat\" + 0.031*\"kirim\" + 0.029*\"sukses\" + 0.025*\"sesuai\" + 0.023*\"toko\" + 0.022*\"layan\" + 0.020*\"beli\"'),\n",
       " (2,\n",
       "  '0.986*\"bantu\" + 0.001*\"latih\" + 0.001*\"beli\" + 0.001*\"bintang\" + 0.000*\"lancar\" + 0.000*\"jaya\" + 0.000*\"paham\" + 0.000*\"trimakasih\" + 0.000*\"sertifikat\" + 0.000*\"kartu\"'),\n",
       " (3,\n",
       "  '0.029*\"bayar\" + 0.022*\"pakai\" + 0.017*\"tolong\" + 0.016*\"baguss\" + 0.016*\"cod\" + 0.015*\"transaksi\" + 0.012*\"shoppe\" + 0.011*\"bgus\" + 0.011*\"gampang\" + 0.011*\"ribet\"')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.doc2idx([\"aplikasi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = model.state.get_lambda()\n",
    "elogbeta = model.state.get_Elogbeta()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lambda_idx(idx, lambdas):\n",
    "    _lambda = []\n",
    "\n",
    "    for l in lambdas:\n",
    "        _lambda.append(l[idx])\n",
    "    \n",
    "    return _lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[792]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.doc2idx([\"latih\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01, 0.01, 431.2721, 0.01]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lambda_idx(792, lambdas)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9bb25bc732f7dedd2d49b595a113c80320e22d6c17d7e5452507f52d8416cf12"
  },
  "kernelspec": {
   "display_name": "Python 3.6.15 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
