{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from joblib import load, dump\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import tokenizer_from_json\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from util.model_helper import Model, ModelLoader\n",
    "from util.ensemble_helper import ModelConcatenate, VotingEnsemble, \\\n",
    "    StackingEnsemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_loader = load\n",
    "keras_loader = keras.models.load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.join('Sentiment Analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch saved model if needed\n",
    "# UNCOMMENT IF MODEL NOT EXISTS\n",
    "#!wget -O ./'Sentiment Analysis'/ignore/Baseline_RF_Sentiment_4.0.E/saved_model1.joblib https://storage.googleapis.com/dionricky-static/baseline_rf_4.0.E.joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_config = {\n",
    "    \"name\": \"Decission Tree\",\n",
    "    \"shortname\": \"DT\",\n",
    "    \"path\": os.path.join(BASE_DIR, \"Baseline\",\n",
    "                        \"Baseline_DT_Sentiment_4.0.E\", \"saved_model.joblib\"),\n",
    "    \"version\": \"4.0.E\",\n",
    "    \"loader\": sklearn_loader\n",
    "}\n",
    "\n",
    "rf_config = {\n",
    "    \"name\": \"Random Forest\",\n",
    "    \"shortname\": \"RF\",\n",
    "    \"path\": os.path.join(BASE_DIR, \"ignore\",\n",
    "                        \"Baseline_RF_Sentiment_4.0.E\", \"saved_model.joblib\"),\n",
    "    \"version\": \"4.0.E\",\n",
    "    \"loader\": sklearn_loader\n",
    "}\n",
    "\n",
    "lr_config = {\n",
    "    \"name\": \"Logistic Regression\",\n",
    "    \"shortname\": \"LR\",\n",
    "    \"path\": os.path.join(BASE_DIR, \"Baseline\",\n",
    "                        \"Baseline_LR_Sentiment_4.0.E\", \"saved_model.joblib\"),\n",
    "    \"version\": \"4.0.E\",\n",
    "    \"loader\": sklearn_loader\n",
    "}\n",
    "\n",
    "nb_config = {\n",
    "    \"name\": \"Naive Bayes\",\n",
    "    \"shortname\": \"NB\",\n",
    "    \"path\": os.path.join(BASE_DIR, \"Baseline\",\n",
    "                        \"Baseline_NB_Sentiment_4.0.E\", \"saved_model.joblib\"),\n",
    "    \"version\": \"4.0.E\",\n",
    "    \"loader\": sklearn_loader\n",
    "}\n",
    "\n",
    "nc_config = {\n",
    "    \"name\": \"Nearest Centroid\",\n",
    "    \"shortname\": \"NC\",\n",
    "    \"path\": os.path.join(BASE_DIR, \"Baseline\",\n",
    "                        \"Baseline_NC_Sentiment_4.0.E\", \"saved_model.joblib\"),\n",
    "    \"version\": \"4.0.E\",\n",
    "    \"loader\": sklearn_loader\n",
    "}\n",
    "\n",
    "svm_config = {\n",
    "    \"name\": \"Support Vector Machine\",\n",
    "    \"shortname\": \"SVM\",\n",
    "    \"path\": os.path.join(BASE_DIR, \"Baseline\",\n",
    "                        \"Baseline_SVM_Sentiment_4.0.E\", \"saved_model.joblib\"),\n",
    "    \"version\": \"4.0.E\",\n",
    "    \"loader\": sklearn_loader\n",
    "}\n",
    "\n",
    "knn_config = {\n",
    "    \"name\": \"K Nearest Neighbor\",\n",
    "    \"shortname\": \"KNN\",\n",
    "    \"path\": os.path.join(BASE_DIR, \"Baseline\",\n",
    "                        \"Baseline_KNN_Sentiment_4.0.E\", \"saved_model.joblib\"),\n",
    "    \"version\": \"4.0.E\",\n",
    "    \"loader\": sklearn_loader\n",
    "}\n",
    "\n",
    "lstm_config = {\n",
    "    \"name\": \"Long Short-term Memory\",\n",
    "    \"shortname\": \"LSTM\",\n",
    "    \"path\": os.path.join(BASE_DIR, \"LSTM\", \"LSTM_Sentiment_4.0.E\"),\n",
    "    \"version\": \"4.0.E\",\n",
    "    \"loader\": keras_loader\n",
    "}\n",
    "\n",
    "cnn_config = {\n",
    "    \"name\": \"Convolutional Neural Network\",\n",
    "    \"shortname\": \"CNN\",\n",
    "    \"path\": os.path.join(BASE_DIR, \"CNN\", \"CNN_Sentiment_5.0\"),\n",
    "    \"version\": \"5.0.E\",\n",
    "    \"loader\": keras_loader\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = os.path.join(BASE_DIR, 'Tokenizer', 'tokens_30k.json')\n",
    "tokenizer_file = open(tokenizer_path, 'r')\n",
    "\n",
    "TOKENIZER = tokenizer_from_json(tokenizer_file.read())\n",
    "\n",
    "tokenizer_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_emojis(sentence):\n",
    "    return [word for word in sentence.split() if str(word.encode('unicode-escape'))[2] == '\\\\' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_text(text):\n",
    "    if type(text) == list \\\n",
    "        or type(text) == np.ndarray \\\n",
    "        or type(text) == pd.Series:\n",
    "        return [preprocessing_text(t) for t in text]\n",
    "\n",
    "    emojis = ' '.join(extract_emojis(text))\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    text = text.lower()\n",
    "\n",
    "    return text + emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_preprocess(texts, vector_size=120):\n",
    "    texts = texts if type(texts) != str else [texts]\n",
    "    texts = preprocessing_text(texts)\n",
    "    seq = TOKENIZER.texts_to_sequences(texts)\n",
    "    return pad_sequences(seq, maxlen=vector_size, padding='post')\n",
    "\n",
    "def sklearn_preprocess(texts):\n",
    "    texts = texts if type(texts) != str else [texts]\n",
    "    texts = preprocessing_text(texts)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Models\n",
    "DT = ModelLoader(**dt_config)\n",
    "DT = Model(\n",
    "        model=DT.load(),\n",
    "        pred_func= lambda m, x: m.predict_proba(sklearn_preprocess(x)),\n",
    "        **DT.get_config())\n",
    "\n",
    "RF = ModelLoader(**rf_config)\n",
    "RF = Model(\n",
    "        model=RF.load(),\n",
    "        pred_func= lambda m, x: m.predict_proba(sklearn_preprocess(x)),\n",
    "        **RF.get_config())\n",
    "\n",
    "LR = ModelLoader(**lr_config)\n",
    "LR = Model(\n",
    "        model=LR.load(),\n",
    "        pred_func= lambda m, x: m.predict_proba(sklearn_preprocess(x)),\n",
    "        **LR.get_config())\n",
    "\n",
    "NB = ModelLoader(**nb_config)\n",
    "NB = Model(\n",
    "        model=NB.load(),\n",
    "        pred_func= lambda m, x: m.predict_proba(sklearn_preprocess(x)),\n",
    "        **NB.get_config())\n",
    "\n",
    "NC = ModelLoader(**nc_config)\n",
    "NC = Model(\n",
    "        model=NC.load(),\n",
    "        pred_func=lambda m, x: m.predict(sklearn_preprocess(x)),\n",
    "        calc_proba_func=lambda y: np.array([1-y, y]).transpose(),\n",
    "        **NC.get_config())\n",
    "\n",
    "SVM = ModelLoader(**svm_config)\n",
    "SVM = Model(\n",
    "        model=SVM.load(),\n",
    "        pred_func=lambda m, x: m.predict(sklearn_preprocess(x)),\n",
    "        calc_proba_func=lambda y: np.array([1-y, y]).transpose(),\n",
    "        **SVM.get_config())\n",
    "\n",
    "KNN = ModelLoader(**knn_config)\n",
    "KNN = Model(\n",
    "        model=KNN.load(),\n",
    "        pred_func=lambda m, x: m.predict_proba(sklearn_preprocess(x)),\n",
    "        **KNN.get_config())\n",
    "\n",
    "LSTM = ModelLoader(**lstm_config)\n",
    "LSTM = Model(\n",
    "        model=LSTM.load(),\n",
    "        pred_func= lambda m, x: m.predict( keras_preprocess(x), workers=2 ),\n",
    "        post_process=lambda y: y.reshape(y.shape[0]),\n",
    "        calc_proba_func=lambda y: np.array([1-y, y]).transpose(),\n",
    "        **LSTM.get_config())\n",
    "\n",
    "CNN = ModelLoader(**cnn_config)\n",
    "CNN = Model(\n",
    "        model=CNN.load(),\n",
    "        pred_func=lambda m, x: m.predict( keras_preprocess(x), workers=2 ),\n",
    "        post_process=lambda y: y.reshape(y.shape[0]),\n",
    "        calc_proba_func=lambda y: np.array([1-y, y]).transpose(),\n",
    "        **CNN.get_config())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = ModelConcatenate([DT, RF, LR, NB, NC, SVM, KNN, LSTM, CNN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = VotingEnsemble(concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_path = '../airflow/credentials/future-data-track-1-sapporo.json'\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    key_path,\n",
    "    scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    ")\n",
    "\n",
    "bigquery_client = bigquery.Client(\n",
    "    project='future-data-track-1',\n",
    "    credentials=credentials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2015, 2016, 2017, 2018, 2019, 2020, 2022] # 2021 is skipped for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = [\n",
    "    bigquery.SchemaField(\"review_id\", \"STRING\", \"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"review\", \"STRING\", \"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"sentiment\", \"STRING\", \"NULLABLE\")\n",
    "]\n",
    "\n",
    "dataset_ref = bigquery.DatasetReference('future-data-track-1', 'sapporo_mart')\n",
    "table_ref = bigquery.TableReference(dataset_ref, 'sentiment_analysis')\n",
    "\n",
    "table = bigquery.Table(table_ref, schema=schema)\n",
    "#table = bigquery_client.create_table(table, exists_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    review_id,\n",
    "    review\n",
    "FROM\n",
    "    `future-data-track-1.sapporo_mart.app_reviews`\n",
    "WHERE EXTRACT(YEAR FROM created_date) = 2021 AND EXTRACT(MONTH FROM created_date) >= 9;\n",
    "\"\"\"\n",
    "\n",
    "query_job = bigquery_client.query(query)\n",
    "df = query_job.to_dataframe()\n",
    "\n",
    "df = df.dropna(axis=0)\n",
    "\n",
    "y = ensemble.predict(df['review'])\n",
    "\n",
    "df['sentiment'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ...]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigquery_client.insert_rows_from_dataframe(\n",
    "    table,\n",
    "    df\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "557dfa72913784ee823994b50ca5bf1f4543af9a8140e691f7ffa1d41b7d01ae"
  },
  "kernelspec": {
   "display_name": "Python 3.6.15 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
